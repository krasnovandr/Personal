expected strength of a term which is randomly distributed in the trainingdocuments with the same frequency. If the term strength of t is not atleast two standard deviations greater than that of the random word,then it is removed from the collection.One advantage of this approach is that it requires no initial supervisionor training data for the feature selection, which is a key requirementin the unsupervised scenario. Of course, the approach can also be usedfor feature selection in either supervised clustering [4] or categorization[100], when such training data is indeed available. One observationabout this approach to feature selection is that it is particularly suited tosimilarity-based clustering because the discriminative nature of the underlyingfeatures is defined on the basis of similarities in the documentsthemselves.